 Hola, soy Luis Serrano y este es Serrano Academy y este video es sobre AdaBoost. En algunos métodos son un super útil para combinar un montón de modelos de la máquina de la máquina de la O.K. a un gran modelo increíble. ¿Y qué significa por modelos de la O.K.? Bueno, te sorprende, pero como longas las modelos son un poco mejor que una gran oportunidad, pueden ser combinadas a un modelo muy bueno. Entonces, si las acuerzas son solo más de 50%, podrías cleveramente combinarlos para un modelo con una muy alta acuerza. Para ilustrar los métodos de assemblos imagínate que tienes que hacer un examen difícil y, digamos, es un examen de la casa de la casa. Entonces, te enlistas a algunos amigos para ayudarte y digamos que esto es de acuerdo, no estamos en la juzgar. En particular, hay dos métodos similares que se llaman de bagging y de boost, los que puedes usar. Los dos consisten de un montón de amigos para ayudarnos con las preguntas de los exames. Vamos a llamar a amigos pocos leonistas, que son un poco difícil primero, pero es significado que emphasizes que nuestros amigos no necesitan ser geniosos para poder ayudar a nosotros a hacer un examen wonderfully bueno. En realidad, como longas nuestros amigos son un poco mejor que la mayoría, estamos bien. Y aquí es cómo el bagging funciona. Para el bagging, vamos a elegir a los amigos randommente y vamos a hacer nuestros amigos responder los test. Una vez que han respondido, pueden ser correctos o malos para algunas de las preguntas, pero eso no importa. Vamos a combinar los respos en algún modo. Puede ser hecho por votar, puede ser hecho por agarrar, ese punto no importa. Hay un mejor manera de hacerlo, pero que es boosting, es el segundo método. Aquí tenemos un modo metodológico para elegir a amigos, así que elegimos a nuestro primer amigo randommente. Entonces, hacemos a nuestro amigo en el examen y vemos cómo ellos hacen. Nuestro primer amigo puede tener algunas fuerzas y algunas weaknesses. Vamos a decir, por ejemplo, que son muy buenas en la maquina, pero mal en la geografía. No hay problema, vamos a elegir a un segundo amigo que es bueno en la geografía para tomar el examen. Y digamos que vamos a combinar estos dos testes y hemos notado que juntos, hicieron la maquina y la geografía, pero hicieron realmente malo en la biología y la física. Vamos a elegir a el tercer amigo para ser muy buenos en la geometría de la física y así y así por el tiempo que elegimos a un nuevo amigo, vamos a asegurar que ellos son buenos en las weaknesses que todos los otros tienen. Eso es llamado boosting y en este video voy a mostrar a vosotras a boost, que es un método boosting muy importante en la maquina. Ok, vamos a empezar con este dataset que tiene dos labios, el triángulo blanco y el cuadro red. Y la idea es para construir un clasificador para que se vea un modelo que puede contar estos dos labios aparte. Entonces, aquí es un buen modelo, es el que construye esta línea entre ellos y clasifica todo a una lado como un triángulo blanco y todo a la otra lado como un cuadro red. Ahora, esto es bueno, pero este clasificador es tan complexo, tiene un mucho de pequeños piezas en la línea, así que es complicado. ¿Puede hacer bien con un simple clasificador? Y con un simple clasificador, significa algo como una línea vertical o una línea horizontal. Estos son algunos de los clasificadores simples que pueden construir. Si estás interesado en los árboles de decisión, esto es un árbol de decisión con sólo uno de los debajo. Si te gusta aprender más sobre los árboles de decisión, recomiendo este video que tengo en mi canal y también es link en los comentarios. Pero con clasificadores no siempre hay que ser árboles de decisión o nada en particular, como longas son simples, fácil de construir y como longas hacen un poco mejor que una random choice, que es 50%, podrá combinarlos a un gran clasificador. Esto es la propiedad increíble de AdaBoost. Puede convertir clasificadores en un buen. Así que vamos a construir algunos simples clasificadores y vamos a llamar estos los leonistas pocos. Vamos a construir leonistas pocos en una manera clave. Vamos a empezar a construir uno de ellos. Vamos a decir que es esta línea vertical aquí,
 que clasifica todo a su izquierda, a su izquierda, y a su izquierda, como un cuadro red. Ahora este cuadro de clasificación es bueno, pero no es perfecto, vamos a necesitar que construyamos más. Y esta es la idea. Cada aprendizaje va a enfocar en las pertenencias de los primeros. ¿Qué son las pertenencias de este cuadro de clasificación? Bueno, como pueden ver, a más de los puntos correctos, pero han hecho tres misiones, que son estos tres cuadros de clasificación que son red. Así que vamos a asegurar que el próximo cuadro de clasificación se enfoca en esos tres puntos. Pero primero, vamos a instalar este cuadro por la utilidad de más tarde. Ahora vamos a construir un nuevo aprendizaje de la década de tiempo en este nuevo set de tiempo. Este nuevo cuadro se enfoca en enfocar más en los errores. Así que digamos que es esta línea horizontal aquí, que actualmente ha hecho muy bien con los tres triangles. Entonces, este también ha hecho algunos misiones, también ha hecho algunos misiones. ¿Cuáles son? Bueno, hay este cuadro de red aquí, que se clasifica como un cuadro de blu, y hay estos dos triangles de blu aquí que se clasifican como cuadros de red. Así que ha hecho tres misiones, pero eso es bueno. Podemos amplificar estos misiones y luego instalar el clasificador para el uso de más tarde. Ahora vamos a construir un nuevo clasificador en estos datos de tiempo. Es mejor que se entiendan los puntos correctos. Y esta línea podría ser esta línea aquí, que clasifica todo a la izquierda como un cuadro de blu y a la derecha como un cuadro de red. Ahora, podríamos continuar ampliando los misiones y construyendo un montón de clasificadores, pero digamos que estamos en el 3 y estamos en el 3. Entonces ahora tenemos tres clasificadores de clasificación. Y nuestro final paso es eso. Con el 3, combinamos los 3 clasificadores de blu y obtenemos este fuerte clasificador aquí. Este es el fuerte clasificador que AdaBoost construye para nosotros. Ahora, eso es el ámbito de AdaBoost, pero hay algunos detalles para Iron, como por qué usar los misiones de caldo, o cómo combinar los clasificadores. Así que eso es lo que vamos a aprender el próximo. Entonces, aquí es cómo construir cada clasificador de blu. Vamos a empezar con nuestro dataset. Y para empezar, vamos a aplicar un peso de 1 a cada uno de los puntos. Entonces, vamos a poner un lector de semana a este dataset. Y digamos que es este aquí. Más de ellos trabajan, pero no puedes hacer demasiado bien, porque el dataset es un poco más complexo que algo que puede ser explotado con un horizontal o un lunes vertical. Entonces, ¿cómo es bueno este? Bueno, vamos a contar cuántos puntos clasifican correctamente y incorrectamente. Casió 7 puntos correctamente, que son estos triángulos de blu aquí y estos squares de red aquí, que son todos en el lado correcto. Y ¿cuántos puntos clasifican correctamente? Estos son 3. Los triángulos de blu aquí que son clasificados como un square de red. Ahora vamos a rescatar los puntos clasificados por algunos factor. Y el factor va a ser 7 por 3. Eso es 2.33. Entonces, estos 3 puntos que son clasificados se rompen por un factor de 2.33. Y por qué es el factor 7 por 3? Porque tenemos 7 correctos y 3 incorrectos. Así que, haz el número de correctos dividido por el número de incorrectos. Este ratio se verá más claro cuando hablamos de los odd más tarde en el vídeo, pero por ahora, digamos que es el número de correctos puntos clasificados dividido por el número de incorrectos puntos clasificados. Entonces, este es nuestro set de data rescalado. Y ahora vamos a jugar el mismo juego de nuevo en order a construir el segundo lunes. Entonces, vamos a construir un lunes de segundo lunes, que se fita este set de data también como posible. Es un set de data rescalado, así que hay más énfasis en esos triángulos de blu que mejor se acercan correctamente. Y ahora veamos cómo bien este lunes de segundo lunes se ha hecho. Vamos a contar el número de correctos puntos correctos. Vamos a tomar el número de sus valores, así que eso va a ser 11. 11 porque hay 2.33 3 veces y entonces 1 4 veces. Entonces, el número de los valores correctos es 11.
 y la cantidad de valores incorrectos es 3 porque es este punto de misclasificación aquí y estos 2 aquí. Entonces ahora vamos a desbloquear los puntos incorrectos por un factor de 11 por 3 porque tenemos 11 correctos y 3 incorrectos. Es 3.67, que significa que estos 3 puntos aquí se desbloquean por un factor de 3.67. Y continuamos jugando el juego. Este es nuestro nuevo data set de rescate y para este data set vamos a fitar un nuevo learner de la semana, se debe obtener esos grandes puntos correctos y es este aquí. Entonces, ¿cuánto es este clasificador? Bueno, ahora la cantidad de valores correctos va a ser 19 porque va a ser estos y estos y la cantidad de puntos correctos va a ser aún 3 porque es este 3 por aquí y podemos continuar escaliando y construyendo leonardos, pero digamos que decidimos que no vamos a dejar ahora, digamos que solo queremos 3 leonardos. Este es un parámetro de hiper que podemos encontrar usando cualquier de sus favoritos métodos de parámetro de la tunación. Entonces en este caso, decidimos que pickar 3 clasificadores, pero podemos pickar tantos como queremos. Y aquí están nuestros 3 leonardos. El primero tenía un score correcto de 7 y 3 correctos, el segundo tenía 11 y 3 y el tercer tenía 19 y 3. Entonces cada uno de los leonardos se asoció a un set de data escala y también asoció a el score correcto y el score incorrecto. Estos números serán importantes cuando se combina a estos 3 leonardos de 3 en un fuerte leónardo, que es lo que vamos a aprender el próximo. Ok, ahora que tenemos los 3 leonardos de 3, vamos a mostrarles cómo combinarlos en un fuerte leónardo. La idea es muy simple, vamos a hacerlos votar. En otros casos, si tenemos un punto aquí y queremos saber el label predictivo, simplemente tenemos que ver qué label es dada a ese punto por los 3 leonardos. Y los labels son red para el primer uno, azul para el segundo y azul para el tercer. Entonces eso es 1 red y 2 blu. Entonces cuando hacemoslos votar, luego vamos a tener que el label es blu. Ahora vamos a hacer eso por cada punto. Así que una forma simple de hacer esto es poner más 1 en las regiones blu y menos 1 en las regiones redas y luego para overeimposar las regiones y luego ver qué son los labels en cada una de estas regiones dada por los clasificadores. Entonces el primer clasificador le da 1 a estas regiones y un 1-1 a estas regiones, el segundo le da 1 a estas regiones y un 1-1 a estas regiones y el tercer 1 a estas regiones y un 1-1 a estas dos. Entonces para saber el label de cada uno de las 6 regiones abajo, todo lo que tenemos que hacer es añadir los 3 números y cuando obtenemos un número que es positivo, luego vamos a decir que el label es blu y cuando obtenemos un label que es negativo, luego vamos a decir que el label es red. Y eso es lo que obtenemos, los labels para todos esos 6 regiones. Puede ser 0, que significa que para esos, el clasificador no realmente sabe si son de blu o red, así que podemos justificarlos randommente, pero la buena noticia es que esto ocurre con una probabilidad muy muy muy pequeña, especialmente si tenemos muchos lectores pocos. Entonces el voto funciona, pero en realidad la manera en que el clasificador combinó es un poco más complicado, pero no mucho, la idea es que combinemoslos con votos de peso. Entonces ¿qué significa esto? Es decir, algunos lectores pocos tienen más fases que otros y eso depende de cómo se hacen. Entonces un lector pocos que aprende el data muy bien tiene más voto que uno que no es tan bueno. Para eso necesitamos un poco de mazo que viene después. Entonces vamos a tracar un poco. Vamos a decir que tenemos un coño y es un
 Entonces, a lo largo de la vida, se retorjarán tres veces de cada cuatro trajes y una vez de los tailos. Por supuesto, puede retorgar nada, pero notemos que la probabilidad de los tailos va a ser tres cuartos. Eso es para tres trajes dividido por los cuatro trajes. Y la probabilidad de los tailos es su complemento, así que es una cuarta, que es una taila dividida por los cuatro trajes. Pero parece que la probabilidad no es exactamente lo que hay aquí. Queremos las odds y la odd es muy similar, excepto, en vez de dividir por el número total de trajes, dividimos el número de trajes por el número de tailos. Entonces, el odd de obtener los trajes va a ser tres por uno. Y el odd de trajes va a ser el inversor multiplicativo, que es una tercera, que es una taila dividida por los tres trajes. La odd es usada mucho en muchos lugares, en particular en el sport, puedes escuchar cosas como los odd de ganar un juego particular o tal. Pero vamos a hacer alguna plada para ver cómo las odd son. Entonces, aquí tenemos las odd de la cabeza, que es tres, y aquí tenemos las odd de los tailos, que es una tercera. Y nos gustaría tener algo simétrico, pero tenemos un pequeño problema, que es que esto no es simétrico. Imagínate si las odd no eran tres y una tercera, pero en vez de que son siete y un séventh. Si su coi fue mucho más biased hacia la cabeza, más hacia las tailas. Y los puntos están aquí y notan que el centro es uno. Y como hacemos la coi más biased hacia las cabezas, las odd de las tailas van más cerca y más cerca al cero, mientras las odd de la cabeza explotan y van muy, muy, muy cerca. Dicimos que convergen hacia la infinidad. Entonces, ese es el problema. ¿Qué podemos hacer para hacer esto un poco más simétrico, para que no es tan pequeño en la izquierda y gigante en la izquierda? Bueno, hay una función que nos va a salvar. Y la función que nos va a salvar es el logaritmo. Recuerden, aquí tenemos las tres, la tercera, la siete y la de los siete. Y aquí es el uno y tenemos una asimetría hacia la izquierda y hacia la derecha. Bueno, no hay problema. Si tomamos el logaritmo, entonces las cosas cambian. Por cierto, estoy tomando el logaritmo natural, que es el e, pero podemos tomar el logaritmo de nada más. Puede ser dos, puede ser diez, puede ser cualquier número que quieras. Y lo mismo se va a llevar. Las cosas están bien escaladas, los números se van a cambiar, pero la simetría no va a cambiar. Entonces, cuando tomamos el logaritmo, entonces el uno va a cero, porque el logaritmo de uno siempre es cero. ¿Y qué pasa con tres? Bueno, el logaritmo de tres es 1.1 y vean esto. El logaritmo de una tercera es menos 1.1, entonces hay simetría. Si hacemos esto para siete, el logaritmo de siete es 1.95, el logaritmo de siete es menos 1.95. Entonces, de nuevo, hay simetría. Y la razón para la simetría es que el logaritmo de uno o dos es el negativo del logaritmo de x. Esto es una función muy popular, es llamada logODS, y también es llamada logGit. Se aparece en todo el machine learning. Y vamos a usarlo para ayudar a combinar los clasificadores. Ok, entonces, reconocemos que tuvimos nuestros tres con los estudiantes aquí, cada uno de ellos con un número correcto y correctos puntos, que fue un suma de los valores correctos y el suma de los valores incorrectos. Ahora, para cada uno de ellos, vamos a calcular la probabilidad de estar correcto para el punto de vista normal, pero la probabilidad de estar correcta. Eso significa que para el primero, tenemos un odds de 7 por 3, para el segundo, 11 por 3, y para el tercer, 19 por 3. Y luego calculamos los odds log o logGit, así que los valores que obtenemos son 0.85.
 1.3 y 1.85. Esto será el escurso de calidad para cada de los leuconarios. En otro idioma, esto es cómo votar cada uno de ellos cuando combinamos. Entonces, ahora con este escurso de calidad vamos a jugar el mismo juego de votación que hemos jugado antes. Eso significa que asignamos 0.85 de votación al primer leuconario, 1.3 al segundo y 1.85 al tercer. Entonces lo que hacemos es multiplicar estos 1's y minus 1's de antes por el escurso de calidad de cada uno de los leuconarios. Entonces vamos a dar 0.85 para estos 1's, 1.3 al segundo y 1.85 para los 1's correspondiendo al leuconario número 3. Y ahora vamos a ponerlos como antes para el primer leuconario, para el segundo y para el tercer. Y cuando le adentremos, tenemos algunos valores que son positivos y negativos. Cuando los valores son positivos, entonces vamos a decir que ese región se clasifica como blu y cuando son negativos se clasifica como rojo. Y de esa manera combinamos estos leuconarios para formar un leuconario fuerte. Y noten que este leuconario es muy bueno porque se maneja para clasificar el整te data set correctamente. Así que eso es cómo la boost de edad funciona. La siguiente cosa que voy a mostrar es un ejemplo de codenario. Entonces ahora vamos a hacer un código. El ejemplo que voy a mostrar a vos aparece en el link de GitHub repository aquí en los comentarios que puedes accesar para frecuencia. Este es el repos de mi libro, El Lerner del Machinero, que contiene una caída de un chapter de la boost, boost, ad boost, random forest, XGBoost, etcétera. Al final del vídeo, puedes ver un link con el código de la discurso, si quieres verlo, pero como dije, el código es accesible a alguien en GitHub. Entonces, el código de la web tiene este set de data aquí y vamos a fitar un model de la boost de edad. Y esto es muy fácil con un par de líneas de código. Primero vamos a importar el clasifier de edad de boost de edad de la pack de la pack de sample de cicatelar. Y luego usamos la función fit, que es todo lo que hacemos. También puedes usar la función score para ver cómo el clasifier está haciendo. Entonces cuando fitamos el clasifier, hace el siguiente. Este es el pálito de los lernos que resultan en lernos fuertes. Nota que lo hizo bastante bien, solo ha hecho un par de mis trucos. Pero nota algo más, hay este parámetro aquí que se llama estimator N, que lo hice hasta 6. Eso significa que usamos 6 lernos lernos para construir este lerno fuertes, y podemos verlo en realidad. Estos son los 6 lernos fuertes aquí. Nota que el lerno fuertes es un superimposición de estos. Pueden ver los lernos que tienen usando esta función estimator y en este caso, son todos al final. Entonces, lo que tenemos es una imposición de todos los lernos fuertes para crear el lerno fuertes. Así que eso es todo, chicos. Gracias por la atención. Si te gusta este video, por favor suscríbete a mi canal, para que puedas ver más contenido. Hice like, compartida o comentario. Puedes también ser un miembro de mi canal por unirme o también puedes apoyarme en Patreon. Mis videos siempre serán frecuentes para todos. Pero si eres un miembro, puedes apoyarme mucho más y puedes obtener algunos perros muy coos como Early Access to Videos, Q&As con mi y tu nombre en los videos. Puedes también seguirme en Twitter, Serano Academy o cheque mi page, que es Serano.academy, donde tengo videos, cursos, postes de blog, etc. Y como mencioné en este video, tengo un libro, Más o menos, Más o menos, Más o menos, y este video hoy aparece en la capta de la libro. Si quieres verlo, hay un link en los comentarios y un codio de descuento por 40%. Así que gracias mucho y nos vemos en el próximo video.